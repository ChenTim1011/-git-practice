## 第十周上課

### 參考資料
[小賴老師20241114投影片](https://docs.google.com/presentation/d/1LbfMIoMFEgRwnrq493oX5nRU10nZ6v6L9q0VT9447IQ/edit#slide=id.g3178ed697b4_2_92)


**1. SRE（網站可靠性工程）相關技能與挑戰：**
- **技能要求：**
  - 熟悉作業系統、網路、程式開發，並掌握 SRE 所需的工具。
  - 具備廣泛的後端知識，避免技能過於狹窄。SRE 工作需要靈活應對不同的技術需求。
- **工作挑戰：**
  - SRE 工作強度高，需隨時待命（on-call），經常面對系統故障，需具備快速反應與解決問題的能力。
  - 成長曲線陡峭，學習壓力大，需快速適應，但是成長得很快!

**2. Troubleshooting（故障排除）流程與報告：**
- **故障排除思維：**
  - **假設-排除循環**：針對系統的觀察結果與執行機制進行假設，並對假設進行測試與排除，直至找到問題根源。
  - **流程：** 問題報告 → 定位/分類 → 檢查 → 診斷 → 測試/修復 → 修復完成。
  - **報告內容**應包含預期現象、實際觀察結果、發生時間點及重現步驟。
- **故障回報後的處理：**
  - **緊急應對措施**：例如將流量導向其他正常運作的主機、服務降級（限制部分功能、降低服務頻率）、重新啟動系統等。必要時應保留證據。
  - **紀錄測試過程**：包括想法、操作過程及結果，建立個人資料庫，幫助日後問題排查。

**3. 測試與修復過程：**
- **測試指南：**
  - 測試應具有互斥性，一次只驗證一個變數，並按問題發生的順序進行測試，以避免誤導性。測試過程應逐步、謹慎進行，以確認變數對系統的影響。
  - 測試應考慮潛在的副作用，例如測試程序是否會佔用大量 CPU，或引發額外問題。
  - 特殊情況如 Deadlock 與 Race condition 難以重現，需針對性進行。
- **記錄時間與紀錄**：測試過程中應重視記錄的時間戳記，以便精準定位問題發生的時間點；每次修改失敗時應能快速回滾，避免系統進一步出現其他問題。

**4. 記錄（Log）管理：**
- **記錄的重要性：**
  - 記錄應包含完整的資訊，如人、事、時、地、物，方便追蹤與分析。每個記錄條目應包含唯一識別碼（UID），以便追蹤。避免記錄敏感資訊，確保安全。
  - **時間戳記：** 使用 UTC 時間，確保跨時區合作的一致性。
  - **記錄層級：** 根據環境設定記錄層級；在測試環境中可收集所有記錄，在生產環境中則需適當篩選。
- **記錄儲存：**
  - 本地保存一份記錄備份，以防網路故障導致資料遺失，並確保記錄的一致性，便於分析與排錯。

**5. 監控與警報系統：**
- **監控指標與警報設計：**
  - 監控硬碟使用量、CPU 利用率等資源，設置適當的閾值（threshold）。關注 HTTP 狀態碼（如 500、404）的異常增長，可能預示 DDoS 攻擊或其他問題。監控資料庫延遲，若從 300ms 增加到 3000ms，可能存在性能問題。
  - 警報系統應收集足夠資訊以確定問題的來源，警報應包含詳細資訊，如哪台機器發生問題，方便快速定位。
- **警報通知：**
  - 使用 AWS SNS 發送電子郵件通知，或透過 Lambda 將警報發送到 Discord 等平台。設定警報的頻率與數量，避免過多警報導致警報疲勞。

**6. 可觀測性與資料收集：**
- **資料收集：**
  - 確定哪些資料對我們最重要，精簡資料收集，避免過多無用資料。前端資料收集時需考慮性能影響，選擇合適的工具如 Sentry。
- **可觀測性：**
  - 設計可觀測性系統時，需考慮資料收集的頻率與方式，確保在異常情況下能獲取足夠的資訊。

**7. 回顧會議（Retro）：**
- **總結教訓**：回顧處理過程中的優缺點，並計劃如何改進，避免或減少類似事件的發生。
  
---
### 1. 基本排查指令
- **curl localhost**：在主機上測試連線，確認服務在本機的正常運行狀況。這與從外部（例如筆電）連線的結果可能會有不同。如果在本機能成功 curl 而從外部無法連線，通常表示網路層或防火牆存在問題。
- **sudo lsof -Pi :80**：列出佔用 80 埠的行程（例如 web 服務）。這有助於檢查是否有其他服務佔用了該埠，導致無法順利運行指定的服務。
- **sudo kill -9 {PID}**：強制終止特定行程（PID），用於清理異常佔用的埠或停用無法正常工作的服務。

### 2. 網路層級排查
- **AWS 安全組（Security Group）**：檢查 AWS 的安全組設定，確認是否允許外部流量進入特定埠（例如 80 或 443 埠）。
- **防火牆（Firewall）**：防火牆層級的設定會影響流量的進入，例如 **ufw** 或 **iptables** 是常見的防火牆工具。可以使用它們來檢查與設定網路存取權限，防止阻擋應用程式的連線。
  - **ufw**：一個較為簡單的防火牆管理工具，通常用於 Ubuntu 系統。
  - **iptables**：一個更為強大且靈活的 Linux 防火牆工具，用來定義流量規則，允許或拒絕特定的網路請求。

### 3. Nginx 排查指令
- **sudo systemctl status nginx --no-pager -l**：檢查 Nginx 服務的狀態，確認是否正常啟動，並查看錯誤訊息。
- **sudo nginx -t**：測試 Nginx 設定檔是否正確。該指令會檢查 Nginx 設定的語法與正確性，若有錯誤會顯示提示，幫助調整設定。
- **Nginx 設定檔位置**：可以從 Nginx 文件中找到設定檔案的位置。此檔案通常位於 /etc/nginx/nginx.conf 或 /etc/nginx/sites-available/default，用於調整伺服器的行為。

### 4. 記錄檢查與管理
- **tail -f xxx.log**：持續查看記錄（log）文件中的變化，適合追蹤 Nginx 或其他應用程式的即時運行狀態。這可以幫助及時捕捉到錯誤或異常行為。
- **Log 的時間與格式**：排查問題時，需注意記錄的時間戳記與格式，以便精確定位問題發生的時間點。檢查 log 時間有助於將問題與特定事件相對應，而良好的 log 格式（包含明確的時間戳和詳細訊息）可以讓排錯過程更具效率。

---

### Troubleshooting Lab - 磁碟使用率相關操作
1. **查看硬碟使用率**
   - **指令：sudo df -h**  
     使用 df -h 指令可以快速檢查硬碟的使用率，以了解是否有空間不足的情況。-h 參數會以人類易讀的格式顯示硬碟使用狀況，便於識別哪些掛載點的空間接近滿載。

2. **清理暫存檔與記錄**
   - **指令：sudo apt-get clean**  
     通常，硬碟空間逐漸被暫存檔（cache）和記錄（log）佔滿，但這些累積可能不容易被察覺。使用 apt-get clean 指令可以清理系統中累積的軟體包暫存，騰出一些空間。

3. **定位大文件**
   - **指令：sudo du -a / | sort -n -r | head -n 5**  
     該指令會遞迴列出目錄及檔案的大小，並找出系統中佔用空間最大的文件。這有助於定位佔用大量硬碟空間的文件，從而判斷是否可以刪除。

4. **擴增硬碟**
   - 當需要更多硬碟空間時，可以在 AWS 上擴增硬碟容量。使用彈性卷（Elastic Volume），可以在不中斷運行的情況下增加硬碟空間，達成「零停機」（Zero Downtime）的需求。

---

### Monitoring - 基礎概念與功能
監控是對系統中的基礎架構（包括硬體、軟體和流程）進行持續測量、收集、儲存、探索和視覺化的過程，旨在回答「何時」與「為何」系統發生特定行為。

1. **監控的重要性**
   - 監控是一種保留證據的方法，能夠記錄系統在特定時間的狀態及行為，提供系統在出現問題時的基礎資料，有助於分析故障根源。

2. **系統理解**
   - 監控能幫助運維人員更清楚地了解系統的常態行為（基線）和高峰時的行為差異。透過對系統的深入理解，運維人員可以更好地進行容量管理、流程改進以及預算規劃等。

3. **監控的三大支柱**
   - **Metrics（指標）**：定量資料，用於量化系統的健康狀況，例如 CPU 使用率、記憶體消耗和回應時間。
   - **Logs（記錄）**：記錄系統的事件，詳細描述事件的性質、發生時間和影響範圍，提供詳細的診斷資料。
   - **Traces（追蹤）**：用於追踪單一請求的完整路徑，幫助識別性能瓶頸和延遲的源頭。

4. **監控事件與設置**
   - **事件（Event）**：任何發生在系統中的可追蹤事件，如在深夜時段 CPU 使用率突然上升。透過事件紀錄，可以分析和定位潛在問題。
   - **監控項目（Monitor）**：指運維人員設定的自動化監控項目，用於持續追蹤系統中關鍵參數，並在發現異常時觸發警報。


---

### Monitoring 監控步驟
監控是一個持續監測系統健康狀況和性能的過程。透過收集、分析和展示關鍵指標，能夠及時發現問題，並有效管理資源。監控過程包含以下幾個步驟：

1. **事件檢測（Event Detection）**
   - 當系統將發生特定事件時，觸發監控的啟動。例如，偵測到即將發生的資源異常或故障徵兆，監控系統可以自動啟動，以便提前採取行動。

2. **資料收集（Data Collection: Metrics, Logs, Traces）**
   - **Metrics（指標）**：定量資料，描述系統的性能（如 CPU 使用率、記憶體消耗、回應時間）。
   - **Logs（記錄）**：詳細記錄系統內部的活動，可用於診斷問題。
   - **Traces（追蹤）**：追踪請求的完整路徑，幫助識別延遲與瓶頸。
   - **資料傳輸**：定期將資料傳送至中央監控伺服器進行儲存和處理。
   - **通知機制**：根據事件觸發信號，通知相關伺服器或團隊。
   - **主動健康檢查**：透過健康檢查的方式主動取得系統狀況。

3. **資料精簡**
   - 收集到的原始資料通常需要整理和壓縮，以便儲存和分析。這一過程包含資料的篩選、編輯和排序，以確保只保留有用的資訊，避免系統負擔過重。

4. **資料分析**
   - 從整理後的資料中提取出重要資訊，例如設定 **SLI（Service Level Indicator）**，提供查詢、告警和系統指標等用途。這一步驟幫助決策者快速掌握系統健康狀況。

5. **資料顯示**
   - **SLO（Service Level Objective）**：基於 SLI 設定的目標，如服務的可用性需達到 99.9%。
   - 通過儀表板（Dashboard）或其他可視化工具，展示監控資料的整體狀況，便於快速檢視系統健康度。

#### 小心「觀測者效應」
- 監控過程中需要避免因為過度測量或監控而影響系統的性能或行為。

---

### 補充：SLI & SLO 概念
- **SLI（Service Level Indicator）**：用於衡量服務品質的實際指標值。例如，請求的回應時間有 99.9% 低於 500ms，這是一個具體的性能表現資料。
- **SLO（Service Level Objective）**：基於 SLI 設定的目標值，通常表達為系統應達到的可用性或性能標準。例子包括「系統可用性需達到 99.9%」，每年停機時間不超過 8.76 小時等。

| SLO 可用性 | 可接受的停機時間（每年） |
|------------|----------------------|
| 90.0%      | 36.5 天              |
| 99.0%      | 3.65 天              |
| 99.9%      | 8.76 小時            |
| 99.95%     | 4.38 小時            |
| 99.99%     | 52.56 分鐘           |
| 99.999%    | 5.26 分鐘            |
| 99.9999%   | 31.5 秒              |

這些資料能幫助設定合理的性能與可靠性目標。

---

### 我們應該要監控什麼？
監控項目的選擇沒有標準答案。監控的設定需要根據系統特性和業務需求來調整，並且需要不斷改進。從能做到的基礎開始做起，持續學習和理解系統行為是提升監控品質的關鍵。

#### 切入點：四種黃金訊號
1. **延遲（Latency）** - 測量系統的效能，例如回應延遲是否達到預期。
2. **錯誤（Errors）** - 測量系統的穩定性，記錄各種操作或服務失敗的次數。
3. **流量（Traffic）** - 測量系統的使用頻率，包含每秒請求數（RPS）、每分鐘請求數（RPM）等指標。
4. **飽和度（Saturation）** - 測量系統資源的使用程度，如資源使用率和 CPU 使用率等。

這些關鍵指標幫助識別系統瓶頸，並提供調整參考依據。

---

### Log 格式 (1) 
1. **一致性**：保持記錄格式一致，便於後續分析。 
2. **唯一識別**：每個請求應分配唯一的 request ID 或 trace ID，以便追蹤特定請求的完整流程。 
3. **適當的內容資訊**：包含使用者 ID、session ID 等內容
資訊。   
 - 不要在記錄中記錄敏感資訊，保護用戶隱私。    
 - **案例**：iRent 資料庫暴露於公開網路且無保護，導致資料洩漏。 

### Log 格式 (2) 
1. **基本訊息**    
  - **時間戳記**：建議使用 UTC 時間，避免因時區不同造成的混淆。   
  - **Log 等級**：定義 Log level，如 TRACE、DEBUG、INFO、WARN、ERROR、FATAL。可根據環境變數來動態調整 Log level，以適應不同的運行環境。   
  - **模組或功能名稱**：標記生成該 Log 的系統模組或功能名稱，幫助更快速定位問題來源。 

### Log 格式 (3) 
1. **結構化記錄（Structured Logging）**：建議以結構化格式儲存記錄，如 JSON。   
- **結構化格式**：有助於查詢與分析，機器可讀性高並能建立一致性。    
- **非結構化格式**：純文字字符串，查找和解析會較為困難。 

### Log Rotate Log Rotate 是一種控制記錄檔案大小、數量和儲存時間的技術，避免單一記錄檔案過大。 
  
  1. **Log 檔案旋轉**：可設置達到特定大小或時間後進行 "rotate"。    
  - 例如，每天生成一個新記錄檔案，或檔案達到 1M 時進行旋轉。 
  
  2. **壓縮（Compress）**：對舊記錄檔案進行壓縮以節省空間。 

  3. **保留與刪除**：設置保留天數或數量限制，超過限制後自動刪除舊記錄。    
  - 確保記錄的保存遵循合規要求，並根據業務需求設定保留政策。  
  
  ### Log Storage 記錄儲存策略的選擇應根據系統需求進行設定，一些常見的集中化記錄儲存工具包括： 
  
  1. **AWS CloudWatch Logs**：雲端記錄管理，適合於 AWS 環境。 
  2. **ELK 堆疊（Elasticsearch + Logstash + Kibana）**：提供強大的記錄分析和可視化功能。 
  3. **Splunk**：商業級記錄管理工具，適用於多樣化的記錄需求。    
   
  考慮：

  - **本地備份需求**：是否需要在本地再保留一份備份，以防止網路中斷。 
  - **成本與策略**：不同儲存位置會有不同的成本與策略考量。  
 
  1. **錯誤訊息分析**：即時應用程式和基礎設施監控。 
  2. **異常行為**：    
  - **大量異常登入失敗**：可能代表系統漏洞或暴力破解。    
  - **API 請求量異常增高**：可能是趨勢變化或潛在攻擊行為。 
  
  3. **商業分析與用戶行為**：點擊流量分析，了解用戶互動行為。 
  
  4. **預測分析與 AI**：透過機器學習分析記錄，預測可能的系統問題並提供自動化警示。  

---

### 監控的考量

當系統使用第三方 API 或部署在雲端平台（如 AWS）時，監控過程中需考慮這些外部服務的狀況。若這些服務出現故障或延遲，可能會對自身系統造成影響。
- **第三方健康檢查**：監控 AWS、Google 等服務的健康狀況（例如 AWS Service Health、Google Service Health），確保外部依賴服務的可用性。
- **案例：機房失火**這樣的意外事件也應納入考慮，設計故障轉移機制以提高系統的彈性和可靠性。

---

### 監控（Monitoring）與可觀測性（Observability）

1. **監控（Monitoring）**
   - 監控是對系統進行觀察（視察）與控制（控制）。然而，實際上控制相對困難，監控的主要目標是持續掌握系統狀況。
   - **例子**：當伺服器 CPU 使用率達到 60% 時，可能啟動自動擴展（auto-scaling）以增加主機。
   
2. **可觀測性（Observability）**
   - 可觀測性強調對未知問題進行探查，深入分析和理解系統的行為。這需要全面收集指標、記錄、追蹤等資料，從而有效定位和解決問題。

---

### 監控的成本
監控系統運作會帶來一定的成本，這些成本包括硬體資源、資料傳輸、維護人力及安全合規等方面的支出。

- **儲存成本**：雖然硬碟單價不高，但隨著資料量增大，總體成本不容小覷。
- **傳輸成本**：資料的頻寬和流量會增加網路傳輸成本。
- **工具費用**：不同監控工具（如 APM、記錄分析工具）會產生額外的支出。
- **人力成本**：監控系統的維護、開發、資料分析等都需投入人力資源。
- **系統效能的影響**：監控可能對系統性能產生影響，需權衡資料收集頻率與效能。
- **安全與合規**：需遵守資料隱私和合規性要求，保障監控資料的安全性。

**案例**：某公司一天的記錄資料量達到 3.5 TB，即使進行了抽樣（sampling），資料量仍相當龐大。

---

### 記錄（Log）的難處

記錄管理的挑戰在於找到合適的平衡點：
1. **記錄記錄過少**：無法提供足夠的資訊來排查問題。
2. **記錄記錄過多**：資訊過於雜亂，影響排查效率，並增加儲存與傳輸的成本。

在記錄記錄時，應包含人、事、時、地、物等關鍵資訊，以便後續分析和追蹤。

---

### 不好的 Log

不佳的記錄通常缺乏具體性，難以幫助問題排查，常見問題包括：
- **資訊混淆**：哪些是問題？哪些只是狀態資訊？
- **缺乏定位**：無法從記錄中快速得知問題發生的位置或時間。
- **錯誤嚴重性不明確**：無法評估問題的嚴重程度。
- **無法追溯用戶行為**：不清楚哪個使用者觸發了問題。
- **錯誤原因不明確**：簡單的“Error”無法描述具體錯誤或影響。

---

